# Prediction Interval Competition II – House Price

## О соревновании Prediction Interval Competition II: House Price

- В этом соревновании на Kaggle участникам нужно не просто предсказывать цену продажи дома, а формировать интервалы предсказаний (prediction intervals), которые должны быть как можно уже, но при этом покрывать истинную цену примерно в 90 % случаев 
Метрика оценки — средний Winkler Interval Score:

- Если истинная цена попала в интервал – score = ширина интервала (upper − lower);

- Если не попала – добавляется штраф, обратнопропорциональный уровню значимости α = 0.1.

- Победители получают цифровые книги и курсы на темы CatBoost, уточнение предсказаний с conformal prediction и др. за лучшее сочетание CatBoost + conformal prediction и т.п

## Что сделано:

Реализован полный pipeline подготовки данных и построения моделей для предсказания доверительных интервалов цен домов:

1. clearing_missing_values(df)
- Удаляет все признаки с пропущенными значениями. Также устанавливает id в качестве индекса, проверяя его уникальность.

2. create_peirs_of_feature(df)
- Генерирует новые признаки — попарные произведения важных числовых переменных, таких как sqft, land_val, beds, imp_val, grade, и др. Это повышает выразительность модели.

3. add_date_features(df)
Работает с датой продажи:

- Извлекает sale_year, sale_month;

- Добавляет синус/косинус-фичи для цикличности месяца;

- Считает возраст дома и годы после последней реновации;

- Удаляет sale_date как ненужный.

4. new_features(df)
Создает продвинутые признаки:

- total_bath как взвешенная сумма разных типов ванных;

- total_view, garage_ratio, structure_share;

- Отношения между ваннами и спальнями;

- Бинарные индикаторы: есть ли подвал, гараж, реновация, вид;

- Комбинированный признак condition_grade и total_area.

5. log_transform_features(df, flag_train=False)
Производит логарифмическое преобразование выбранных признаков (в основном, интеракции между важными числовыми переменными), чтобы:

- Сгладить распределение признаков;

- Уменьшить влияние выбросов;

- Улучшить обобщающую способность модели.

Перечень преобразуемых признаков зависит от значения flag_train:

- Для обучающей выборки логарифмируются как interaction-фичи, так и базовые признаки (sale_price, land_val, imp_val, и т.п.);

- Для тестовой выборки — только те признаки, что прошли отбор при обучении.

6. remove_outliers_iqr(...)
Функция для удаления выбросов из тренировочной выборки:

- Использует один из методов: z-score или IQR (межквартильный размах);

- Работает только по топ-N признакам, наиболее коррелированным с sale_price;

- Удаляет строки, где одновременно наблюдаются выбросы по нескольким (например, 2+) важным признакам.

Параметры:

- method: способ оценки (zscore или iqr);

- z_thresh: порог для zscore;

- iqr_factor: множитель для границ по IQR;

- top_n: число признаков по корреляции;

- max_outlier_features: сколько признаков может быть выбросами одновременно, чтобы строка была удалена.

7. target_encode_all(train_df, val_df, test_df, target_col="sale_price", n_splits=5)
Функция выполняет кросс-валидационный target encoding для категориальных признаков. Это предотвращает утечку данных (data leakage) и стабилизирует значения, особенно для редких категорий.

Что делает:

- Определяет категориальные признаки — все object-типы, кроме целевой переменной.

- Сбрасывает индексы у всех датафреймов — для безопасного обращения по позициям.

- По каждому категориальному признаку:

- Разбивает train_df на n_splits фолдов.

Для каждой фолды:

- Считает среднее значение sale_price для каждой категории (на train-части фолда).

- Применяет .map() на валидационную часть фолда.

- Сохраняет OOF-предсказания в виде нового признака col_te.

- Применяет .map() ко всему val_df и test_df — без кросс-валидации, просто маппингом по train-статистике.

- Удаляет оригинальные категориальные признаки (object) и колонку sale_price (опционально).

- Проверяет, что длины датафреймов не изменились.

## Моделирование

Используется LightGBM:

- первая модель (mean_model) предсказывает логарифм средней цены (mu);

- вторая модель (sigma_model) предсказывает логарифм стандартного отклонения (sigma).

На этапе предсказания:

- модельные значения mu и sigma превращаются обратно в пространство цен через expm1;

## Финальный output

Собирается DataFrame для submission.csv, содержащий:

- id — идентификатор объекта;

- pi_lower — нижняя граница интервала;

- pi_upper — верхняя граница.

Файл сохраняется и готов к загрузке на Kaggle.